use std::time::Duration;

use futures::Stream;
use proto::TenantTimelineId as ProtoTenantTimelineId;
use tokio_util::sync::CancellationToken;
use tonic::Status;
use tonic::transport::Endpoint;
use tracing::{error, info, warn};
use utils::backoff::{
    DEFAULT_BASE_BACKOFF_SECONDS, DEFAULT_MAX_BACKOFF_SECONDS, exponential_backoff,
};
use utils::id::{TenantId, TenantTimelineId, TimelineId};

// Code generated by protobuf.
pub mod proto {
    // Tonic does derives as `#[derive(Clone, PartialEq, ::prost::Message)]`
    // we don't use these types for anything but broker data transmission,
    // so it's ok to ignore this one.
    #![allow(clippy::derive_partial_eq_without_eq)]
    tonic::include_proto!("storage_broker");
}

pub mod metrics;

// Re-exports to avoid direct tonic dependency in user crates.
pub use hyper::Uri;
pub use tonic::transport::{Certificate, ClientTlsConfig};
pub use tonic::{Code, Request, Streaming};
use utils::shard::TenantShardId;

pub const DEFAULT_LISTEN_ADDR: &str = "127.0.0.1:50051";
pub const DEFAULT_ENDPOINT: &str = const_format::formatcp!("http://{DEFAULT_LISTEN_ADDR}");

pub const DEFAULT_KEEPALIVE_INTERVAL: &str = "5000 ms";
pub const DEFAULT_CONNECT_TIMEOUT: Duration = Duration::from_millis(5000);

#[derive(Clone)]
pub struct TimelineUpdatesSubscriber {
    client: proto::broker_service_client::BrokerServiceClient<tonic::transport::Channel>,
}

/// Wrapper type to weed out all places in the codebase that interact directly with the gRPC generated code.
/// We want all to go through the facade structs above so we can implement brokerless mode in the future.
pub struct BrokerClientChannel {
    client: proto::broker_service_client::BrokerServiceClient<tonic::transport::Channel>,
}

pub struct TimelineShardUpdate {
    pub is_discovery: bool,
    pub inner: proto::SafekeeperDiscoveryResponse,
}

pub enum SubscriberError {
    Cancelled,
}

impl TimelineUpdatesSubscriber {
    pub fn new(service_client: BrokerClientChannel) -> Self {
        Self {
            client: service_client.client.clone(),
        }
    }
    pub fn subscribe(
        &mut self,
        tenant_shard_id: TenantShardId,
        timeline_id: TimelineId,
        cancel: &CancellationToken,
    ) -> impl Stream<Item = Result<TimelineShardUpdate, SubscriberError>> {
        async_stream::stream! {
            let mut attempt = 0;
            'resubscribe: loop {
                exponential_backoff(
                    attempt,
                    DEFAULT_BASE_BACKOFF_SECONDS,
                    DEFAULT_MAX_BACKOFF_SECONDS,
                    cancel,
                )
                .await;
                attempt += 1;

                use proto::*;
                // subscribe to the specific timeline
                let request = SubscribeByFilterRequest {
                    types: vec![
                        TypeSubscription {
                            r#type: MessageType::SafekeeperTimelineInfo as i32,
                        },
                        TypeSubscription {
                            r#type: MessageType::SafekeeperDiscoveryResponse as i32,
                        },
                    ],
                    tenant_timeline_id: Some(FilterTenantTimelineId {
                        enabled: true,
                        tenant_timeline_id: Some(ProtoTenantTimelineId {
                            tenant_id: tenant_shard_id.tenant_id.as_ref().to_owned(),
                            timeline_id: timeline_id.as_ref().to_owned(),
                        }),
                    }),
                };

                let res = tokio::select! {
                    r = self.client.subscribe_by_filter(request) => { r }
                    _ = cancel.cancelled() => { yield Err(SubscriberError::Cancelled); return; }
                };
                let mut update_stream = match res
                 {
                    Ok(resp) => {
                        resp.into_inner()
                    }
                    Err(e) => {
                        // Safekeeper nodes can stop pushing timeline updates to the broker, when no new writes happen and
                        // entire WAL is streamed. Keep this noticeable with logging, but do not warn/error.
                        info!(
                            attempt, "failed to subscribe: {e:#}"
                        );
                        continue 'resubscribe;
                    }
                };
                loop {
                    let broker_update = tokio::select!{
                        _ = cancel.cancelled() => {
                            yield Err(SubscriberError::Cancelled); return;
                        }
                        update = update_stream.message() => { update }
                    };
                    match broker_update {
                        Ok(Some(typed_msg)) => {
                            let mut is_discovery = false;
                            let timeline_update = match typed_msg.r#type() {
                                MessageType::SafekeeperTimelineInfo => {
                                    let info = match typed_msg.safekeeper_timeline_info {
                                        Some(info) => info,
                                        None => {
                                            warn!("bad proto message from broker: no safekeeper_timeline_info");
                                            continue 'resubscribe;
                                        }
                                    };
                                    SafekeeperDiscoveryResponse {
                                        safekeeper_id: info.safekeeper_id,
                                        tenant_timeline_id: info.tenant_timeline_id,
                                        commit_lsn: info.commit_lsn,
                                        safekeeper_connstr: info.safekeeper_connstr,
                                        availability_zone: info.availability_zone,
                                        standby_horizon: info.standby_horizon,
                                    }
                                }
                                MessageType::SafekeeperDiscoveryResponse => {
                                    is_discovery = true;
                                    match typed_msg.safekeeper_discovery_response {
                                        Some(response) => response,
                                        None => {
                                            warn!("bad proto message from broker: no safekeeper_discovery_response");
                                            continue 'resubscribe;
                                        }
                                    }
                                }
                                _ => {
                                    // unexpected message
                                    warn!("unexpected message from broker: {typed_msg:?}");
                                    continue 'resubscribe;
                                }
                            };
                            attempt = 0; // reset backoff iff we received a valid update
                            yield Ok(TimelineShardUpdate{is_discovery, inner: timeline_update });
                        },
                        Err(status) => {
                            match status.code() {
                                Code::Unknown if status.message().contains("stream closed because of a broken pipe") || status.message().contains("connection reset") || status.message().contains("error reading a body from connection") => {
                                    // tonic's error handling doesn't provide a clear code for disconnections: we get
                                    // "h2 protocol error: error reading a body from connection: stream closed because of a broken pipe"
                                    // => https://github.com/neondatabase/neon/issues/9562
                                    info!("broker disconnected: {status}");
                                },
                                _ => {
                                    warn!("broker subscription failed: {status}");
                                }
                            }
                            continue 'resubscribe;
                        }
                        Ok(None) => {
                            error!("broker subscription stream ended"); // can't happen
                            continue 'resubscribe;
                        }
                    }
                }
            }
        }
    }
}

// Create connection object configured to run TLS if schema starts with https://
// and plain text otherwise. Connection is lazy, only endpoint sanity is
// validated here.
//
// NB: this function is not async, but still must be run on a tokio runtime thread
// because that's a requirement of tonic_endpoint.connect_lazy()'s Channel::new call.
pub fn connect<U>(
    endpoint: U,
    keepalive_interval: Duration,
    tls_config: ClientTlsConfig,
) -> anyhow::Result<BrokerClientChannel>
where
    U: std::convert::TryInto<Uri>,
    U::Error: std::error::Error + Send + Sync + 'static,
{
    let uri: Uri = endpoint.try_into()?;
    let mut tonic_endpoint: Endpoint = uri.into();
    // If schema starts with https, start encrypted connection; do plain text
    // otherwise.
    if let Some("https") = tonic_endpoint.uri().scheme_str() {
        // if there's no default provider and both ring+aws-lc-rs are enabled
        // this the tls settings on tonic will not work.
        // erroring is ok.
        rustls::crypto::ring::default_provider()
            .install_default()
            .ok();
        tonic_endpoint = tonic_endpoint.tls_config(tls_config)?;
    }
    tonic_endpoint = tonic_endpoint
        .http2_keep_alive_interval(keepalive_interval)
        .keep_alive_while_idle(true)
        .connect_timeout(DEFAULT_CONNECT_TIMEOUT);
    //  keep_alive_timeout is 20s by default on both client and server side
    let channel = tonic_endpoint.connect_lazy();
    Ok(BrokerClientChannel {
        client: proto::broker_service_client::BrokerServiceClient::new(channel),
    })
}

// parse variable length bytes from protobuf
#[allow(clippy::result_large_err, reason = "TODO")]
pub fn parse_proto_ttid(proto_ttid: &ProtoTenantTimelineId) -> Result<TenantTimelineId, Status> {
    let tenant_id = TenantId::from_slice(&proto_ttid.tenant_id)
        .map_err(|e| Status::new(Code::InvalidArgument, format!("malformed tenant_id: {}", e)))?;
    let timeline_id = TimelineId::from_slice(&proto_ttid.timeline_id).map_err(|e| {
        Status::new(
            Code::InvalidArgument,
            format!("malformed timeline_id: {}", e),
        )
    })?;
    Ok(TenantTimelineId {
        tenant_id,
        timeline_id,
    })
}
