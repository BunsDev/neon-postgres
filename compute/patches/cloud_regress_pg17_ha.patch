diff --git a/src/test/regress/sql/aggregates.sql b/src/test/regress/sql/aggregates.sql
index fe4d89aec6..76ac6d3624 100644
--- a/src/test/regress/sql/aggregates.sql
+++ b/src/test/regress/sql/aggregates.sql
@@ -79,16 +79,16 @@ SELECT var_pop('nan'::numeric), var_samp('nan'::numeric);
 SELECT stddev_pop('nan'::numeric), stddev_samp('nan'::numeric);
 
 -- verify correct results for null and NaN inputs
-select sum(null::int4) from generate_series(1,3);
-select sum(null::int8) from generate_series(1,3);
-select sum(null::numeric) from generate_series(1,3);
-select sum(null::float8) from generate_series(1,3);
-select avg(null::int4) from generate_series(1,3);
-select avg(null::int8) from generate_series(1,3);
-select avg(null::numeric) from generate_series(1,3);
-select avg(null::float8) from generate_series(1,3);
-select sum('NaN'::numeric) from generate_series(1,3);
-select avg('NaN'::numeric) from generate_series(1,3);
+select sum(null::int4) from generate_series(1,30);
+select sum(null::int8) from generate_series(1,30);
+select sum(null::numeric) from generate_series(1,30);
+select sum(null::float8) from generate_series(1,30);
+select avg(null::int4) from generate_series(1,30);
+select avg(null::int8) from generate_series(1,30);
+select avg(null::numeric) from generate_series(1,30);
+select avg(null::float8) from generate_series(1,30);
+select sum('NaN'::numeric) from generate_series(1,30);
+select avg('NaN'::numeric) from generate_series(1,30);
 
 -- verify correct results for infinite inputs
 SELECT sum(x::float8), avg(x::float8), var_pop(x::float8)
diff --git a/src/test/regress/sql/amutils.sql b/src/test/regress/sql/amutils.sql
index 06e7fa10d9..f54db55206 100644
--- a/src/test/regress/sql/amutils.sql
+++ b/src/test/regress/sql/amutils.sql
@@ -84,7 +84,7 @@ select col, prop, pg_index_column_has_property(o, col, prop)
        (values (1,'orderable'),(2,'asc'),(3,'desc'),
                (4,'nulls_first'),(5,'nulls_last'),
                (6, 'bogus')) v2(idx,prop),
-       generate_series(1,4) col
+       generate_series(1,40) col
  order by col, idx;
 
 CREATE INDEX foocover ON foo (f1) INCLUDE (f2,f3);
@@ -95,5 +95,5 @@ select col, prop, pg_index_column_has_property(o, col, prop)
                (4,'nulls_first'),(5,'nulls_last'),
                (6,'distance_orderable'),(7,'returnable'),
                (8, 'bogus')) v2(idx,prop),
-       generate_series(1,3) col
+       generate_series(1,30) col
  order by col, idx;
diff --git a/src/test/regress/sql/arrays.sql b/src/test/regress/sql/arrays.sql
index 305371deba..fdbe299c01 100644
--- a/src/test/regress/sql/arrays.sql
+++ b/src/test/regress/sql/arrays.sql
@@ -300,7 +300,7 @@ SELECT array_positions(ARRAY[[1,2],[3,4]], 4);
 SELECT array_positions(ARRAY[1,2,3,4,5,6,1,2,3,4,5,6], NULL);
 SELECT array_positions(ARRAY[1,2,3,NULL,5,6,1,2,3,NULL,5,6], NULL);
 SELECT array_length(array_positions(ARRAY(SELECT 'AAAAAAAAAAAAAAAAAAAAAAAAA'::text || i % 10
-                                          FROM generate_series(1,100) g(i)),
+                                          FROM generate_series(1,1000) g(i)),
                                   'AAAAAAAAAAAAAAAAAAAAAAAAA5'), 1);
 
 DO $$
diff --git a/src/test/regress/sql/bitmapops.sql b/src/test/regress/sql/bitmapops.sql
index 498f4721b5..9b56db06d7 100644
--- a/src/test/regress/sql/bitmapops.sql
+++ b/src/test/regress/sql/bitmapops.sql
@@ -16,7 +16,7 @@ CREATE TABLE bmscantest (a int, b int, t text);
 
 INSERT INTO bmscantest
   SELECT (r%53), (r%59), 'foooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo'
-  FROM generate_series(1,70000) r;
+  FROM generate_series(1,700000) r;
 
 CREATE INDEX i_bmtest_a ON bmscantest(a);
 CREATE INDEX i_bmtest_b ON bmscantest(b);
diff --git a/src/test/regress/sql/brin.sql b/src/test/regress/sql/brin.sql
index 695cfad4be..88a0e79224 100644
--- a/src/test/regress/sql/brin.sql
+++ b/src/test/regress/sql/brin.sql
@@ -461,7 +461,7 @@ DROP TABLE brintest_2;
 
 -- test brin cost estimates behave sanely based on correlation of values
 CREATE TABLE brin_test (a INT, b INT);
-INSERT INTO brin_test SELECT x/100,x%100 FROM generate_series(1,10000) x(x);
+INSERT INTO brin_test SELECT x/100,x%100 FROM generate_series(1,100000) x(x);
 CREATE INDEX brin_test_a_idx ON brin_test USING brin (a) WITH (pages_per_range = 2);
 CREATE INDEX brin_test_b_idx ON brin_test USING brin (b) WITH (pages_per_range = 2);
 VACUUM ANALYZE brin_test;
@@ -476,7 +476,7 @@ CREATE TABLE brintest_3 (a text, b text, c text, d text);
 
 -- long random strings (~2000 chars each, so ~6kB for min/max on two
 -- columns) to trigger toasting
-WITH rand_value AS (SELECT string_agg(fipshash(i::text),'') AS val FROM generate_series(1,60) s(i))
+WITH rand_value AS (SELECT string_agg(fipshash(i::text),'') AS val FROM generate_series(1,600) s(i))
 INSERT INTO brintest_3
 SELECT val, val, val, val FROM rand_value;
 
@@ -495,7 +495,7 @@ VACUUM brintest_3;
 -- retry insert with a different random-looking (but deterministic) value
 -- the value is different, and so should replace either min or max in the
 -- brin summary
-WITH rand_value AS (SELECT string_agg(fipshash((-i)::text),'') AS val FROM generate_series(1,60) s(i))
+WITH rand_value AS (SELECT string_agg(fipshash((-i)::text),'') AS val FROM generate_series(1,600) s(i))
 INSERT INTO brintest_3
 SELECT val, val, val, val FROM rand_value;
 
diff --git a/src/test/regress/sql/brin_bloom.sql b/src/test/regress/sql/brin_bloom.sql
index 5d499208e3..e18f43c576 100644
--- a/src/test/regress/sql/brin_bloom.sql
+++ b/src/test/regress/sql/brin_bloom.sql
@@ -365,7 +365,7 @@ SELECT brin_summarize_range('brin_summarize_bloom_idx', 4294967296);
 
 -- test brin cost estimates behave sanely based on correlation of values
 CREATE TABLE brin_test_bloom (a INT, b INT);
-INSERT INTO brin_test_bloom SELECT x/100,x%100 FROM generate_series(1,10000) x(x);
+INSERT INTO brin_test_bloom SELECT x/100,x%100 FROM generate_series(1,100000) x(x);
 CREATE INDEX brin_test_bloom_a_idx ON brin_test_bloom USING brin (a) WITH (pages_per_range = 2);
 CREATE INDEX brin_test_bloom_b_idx ON brin_test_bloom USING brin (b) WITH (pages_per_range = 2);
 VACUUM ANALYZE brin_test_bloom;
diff --git a/src/test/regress/sql/brin_multi.sql b/src/test/regress/sql/brin_multi.sql
index 55349b4e1f..48fc3f5584 100644
--- a/src/test/regress/sql/brin_multi.sql
+++ b/src/test/regress/sql/brin_multi.sql
@@ -377,7 +377,7 @@ SELECT brin_desummarize_range('brinidx_multi', 100000000);
 
 -- test building an index with many values, to force compaction of the buffer
 CREATE TABLE brin_large_range (a int4);
-INSERT INTO brin_large_range SELECT i FROM generate_series(1,10000) s(i);
+INSERT INTO brin_large_range SELECT i FROM generate_series(1,100000) s(i);
 CREATE INDEX brin_large_range_idx ON brin_large_range USING brin (a int4_minmax_multi_ops);
 DROP TABLE brin_large_range;
 
@@ -412,7 +412,7 @@ SELECT brin_summarize_range('brin_summarize_multi_idx', 4294967296);
 
 -- test brin cost estimates behave sanely based on correlation of values
 CREATE TABLE brin_test_multi (a INT, b INT);
-INSERT INTO brin_test_multi SELECT x/100,x%100 FROM generate_series(1,10000) x(x);
+INSERT INTO brin_test_multi SELECT x/100,x%100 FROM generate_series(1,100000) x(x);
 CREATE INDEX brin_test_multi_a_idx ON brin_test_multi USING brin (a) WITH (pages_per_range = 2);
 CREATE INDEX brin_test_multi_b_idx ON brin_test_multi USING brin (b) WITH (pages_per_range = 2);
 VACUUM ANALYZE brin_test_multi;
@@ -428,7 +428,7 @@ CREATE TABLE brin_test_multi_1 (a INT, b BIGINT) WITH (fillfactor=10);
 INSERT INTO brin_test_multi_1
 SELECT i/5 + mod(911 * i + 483, 25),
        i/10 + mod(751 * i + 221, 41)
-  FROM generate_series(1,1000) s(i);
+  FROM generate_series(1,10000) s(i);
 
 CREATE INDEX brin_test_multi_1_idx_1 ON brin_test_multi_1 USING brin (a int4_minmax_multi_ops) WITH (pages_per_range=5);
 CREATE INDEX brin_test_multi_1_idx_2 ON brin_test_multi_1 USING brin (b int8_minmax_multi_ops) WITH (pages_per_range=5);
@@ -489,7 +489,7 @@ TRUNCATE brin_test_multi_1;
 INSERT INTO brin_test_multi_1
 SELECT i/5 + mod(911 * i + 483, 25),
        i/10 + mod(751 * i + 221, 41)
-  FROM generate_series(1,1000) s(i);
+  FROM generate_series(1,10000) s(i);
 
 -- int: less than
 SELECT COUNT(*) FROM brin_test_multi_1 WHERE a < 37;
@@ -545,7 +545,7 @@ RESET enable_seqscan;
 -- do some inequality tests for varlena data types
 CREATE TABLE brin_test_multi_2 (a UUID) WITH (fillfactor=10);
 INSERT INTO brin_test_multi_2
-SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1,1000) s(i)) foo) bar ORDER BY c + 25 * random();
+SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1,10000) s(i)) foo) bar ORDER BY c + 25 * random();
 
 CREATE INDEX brin_test_multi_2_idx ON brin_test_multi_2 USING brin (a uuid_minmax_multi_ops) WITH (pages_per_range=5);
 
@@ -570,7 +570,7 @@ SELECT COUNT(*) FROM brin_test_multi_2 WHERE a = '86e50149-6586-6131-2a9e-0b3555
 
 TRUNCATE brin_test_multi_2;
 INSERT INTO brin_test_multi_2
-SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1,1000) s(i)) foo) bar ORDER BY c + 25 * random();
+SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1,10000) s(i)) foo) bar ORDER BY c + 25 * random();
 
 SELECT COUNT(*) FROM brin_test_multi_2 WHERE a < '3d914f93-48c9-cc0f-f8a7-9716700b9fcd';
 
@@ -595,12 +595,12 @@ SET datestyle TO iso;
 -- values close to timestamp minimum
 INSERT INTO brin_timestamp_test
 SELECT '4713-01-01 00:00:01 BC'::timestamptz + (i || ' seconds')::interval
-  FROM generate_series(1,30) s(i);
+  FROM generate_series(1,300) s(i);
 
 -- values close to timestamp maximum
 INSERT INTO brin_timestamp_test
 SELECT '294276-12-01 00:00:01'::timestamptz + (i || ' seconds')::interval
-  FROM generate_series(1,30) s(i);
+  FROM generate_series(1,300) s(i);
 
 CREATE INDEX ON brin_timestamp_test USING brin (a timestamptz_minmax_multi_ops) WITH (pages_per_range=1);
 DROP TABLE brin_timestamp_test;
diff --git a/src/test/regress/sql/btree_index.sql b/src/test/regress/sql/btree_index.sql
index 0d2a33f370..69368bf797 100644
--- a/src/test/regress/sql/btree_index.sql
+++ b/src/test/regress/sql/btree_index.sql
@@ -203,7 +203,7 @@ select * from btree_bpchar where f1::bpchar like 'foo%';
 select * from btree_bpchar where f1::bpchar like 'foo%';
 
 -- get test coverage for "single value" deduplication strategy:
-insert into btree_bpchar select 'foo' from generate_series(1,1500);
+insert into btree_bpchar select 'foo' from generate_series(1,15000);
 
 --
 -- Perform unique checking, with and without the use of deduplication
@@ -253,7 +253,7 @@ from generate_series(1, 130) g;
 -- Test for multilevel page deletion
 --
 CREATE TABLE delete_test_table (a bigint, b bigint, c bigint, d bigint);
-INSERT INTO delete_test_table SELECT i, 1, 2, 3 FROM generate_series(1,80000) i;
+INSERT INTO delete_test_table SELECT i, 1, 2, 3 FROM generate_series(1,800000) i;
 ALTER TABLE delete_test_table ADD PRIMARY KEY (a,b,c,d);
 -- Delete most entries, and vacuum, deleting internal pages and creating "fast
 -- root"
@@ -267,7 +267,7 @@ VACUUM delete_test_table;
 --
 -- The vacuum above should've turned the leaf page into a fast root. We just
 -- need to insert some rows to cause the fast root page to split.
-INSERT INTO delete_test_table SELECT i, 1, 2, 3 FROM generate_series(1,1000) i;
+INSERT INTO delete_test_table SELECT i, 1, 2, 3 FROM generate_series(1,10000) i;
 
 -- Test unsupported btree opclass parameters
 create index on btree_tall_tbl (id int4_ops(foo=1));
diff --git a/src/test/regress/sql/copy.sql b/src/test/regress/sql/copy.sql
index e2dd24cb35..1db1849d6a 100644
--- a/src/test/regress/sql/copy.sql
+++ b/src/test/regress/sql/copy.sql
@@ -81,9 +81,9 @@ alter table parted_copytest attach partition parted_copytest_a2 for values in(2)
 
 -- We must insert enough rows to trigger multi-inserts.  These are only
 -- enabled adaptively when there are few enough partition changes.
-insert into parted_copytest select x,1,'One' from generate_series(1,1000) x;
-insert into parted_copytest select x,2,'Two' from generate_series(1001,1010) x;
-insert into parted_copytest select x,1,'One' from generate_series(1011,1020) x;
+insert into parted_copytest select x,1,'One' from generate_series(1,10000) x;
+insert into parted_copytest select x,2,'Two' from generate_series(10001,10100) x;
+insert into parted_copytest select x,1,'One' from generate_series(10101,10200) x;
 
 \set filename :abs_builddir '/results/parted_copytest.csv'
 copy (select * from parted_copytest order by a) to :'filename';
diff --git a/src/test/regress/sql/copy2.sql b/src/test/regress/sql/copy2.sql
index 6b75b6c7ea..128641833a 100644
--- a/src/test/regress/sql/copy2.sql
+++ b/src/test/regress/sql/copy2.sql
@@ -152,7 +152,7 @@ COPY x from stdin WHERE a = max(x.b);
 
 COPY x from stdin WHERE a IN (SELECT 1 FROM x);
 
-COPY x from stdin WHERE a IN (generate_series(1,5));
+COPY x from stdin WHERE a IN (generate_series(1,50));
 
 COPY x from stdin WHERE a = row_number() over(b);
 
diff --git a/src/test/regress/sql/create_am.sql b/src/test/regress/sql/create_am.sql
index 754fe0c694..482884bbc2 100644
--- a/src/test/regress/sql/create_am.sql
+++ b/src/test/regress/sql/create_am.sql
@@ -166,7 +166,7 @@ ORDER BY classid, objid, objsubid;
 
 -- ALTER TABLE SET ACCESS METHOD
 CREATE TABLE heaptable USING heap AS
-  SELECT a, repeat(a::text, 100) FROM generate_series(1,9) AS a;
+  SELECT a, repeat(a::text, 100) FROM generate_series(1,90) AS a;
 SELECT amname FROM pg_class c, pg_am am
   WHERE c.relam = am.oid AND c.oid = 'heaptable'::regclass;
 -- Switching to heap2 adds new dependency entry to the AM.
diff --git a/src/test/regress/sql/create_index.sql b/src/test/regress/sql/create_index.sql
index e296891cab..ce939f2e10 100644
--- a/src/test/regress/sql/create_index.sql
+++ b/src/test/regress/sql/create_index.sql
@@ -1259,7 +1259,7 @@ REINDEX SCHEMA schema_to_reindex; -- failure, schema does not exist
 CREATE SCHEMA schema_to_reindex;
 SET search_path = 'schema_to_reindex';
 CREATE TABLE table1(col1 SERIAL PRIMARY KEY);
-INSERT INTO table1 SELECT generate_series(1,400);
+INSERT INTO table1 SELECT generate_series(1,4000);
 CREATE TABLE table2(col1 SERIAL PRIMARY KEY, col2 TEXT NOT NULL);
 INSERT INTO table2 SELECT generate_series(1,400), 'abc';
 CREATE INDEX ON table2(col2);
diff --git a/src/test/regress/sql/create_index_spgist.sql b/src/test/regress/sql/create_index_spgist.sql
index 660bfc6193..f32a504175 100644
--- a/src/test/regress/sql/create_index_spgist.sql
+++ b/src/test/regress/sql/create_index_spgist.sql
@@ -6,7 +6,7 @@ CREATE TABLE quad_point_tbl AS
     SELECT point(unique1,unique2) AS p FROM tenk1;
 
 INSERT INTO quad_point_tbl
-    SELECT '(333.0,400.0)'::point FROM generate_series(1,1000);
+    SELECT '(333.0,400.0)'::point FROM generate_series(1,10000);
 
 INSERT INTO quad_point_tbl VALUES (NULL), (NULL), (NULL);
 
diff --git a/src/test/regress/sql/create_table.sql b/src/test/regress/sql/create_table.sql
index 1fd4cbfa7e..51021e195f 100644
--- a/src/test/regress/sql/create_table.sql
+++ b/src/test/regress/sql/create_table.sql
@@ -74,7 +74,7 @@ CREATE TABLE default_expr_agg (a int DEFAULT (avg(1)));
 -- invalid use of subquery
 CREATE TABLE default_expr_agg (a int DEFAULT (select 1));
 -- invalid use of set-returning function
-CREATE TABLE default_expr_agg (a int DEFAULT (generate_series(1,3)));
+CREATE TABLE default_expr_agg (a int DEFAULT (generate_series(1,30)));
 
 -- Verify that subtransaction rollback restores rd_createSubid.
 BEGIN;
diff --git a/src/test/regress/sql/fast_default.sql b/src/test/regress/sql/fast_default.sql
index a21b406e65..71fd1396ac 100644
--- a/src/test/regress/sql/fast_default.sql
+++ b/src/test/regress/sql/fast_default.sql
@@ -53,7 +53,7 @@ end;
 $func$;
 
 CREATE TABLE has_volatile AS
-SELECT * FROM generate_series(1,10) id;
+SELECT * FROM generate_series(1,100) id;
 
 
 CREATE EVENT TRIGGER has_volatile_rewrite
@@ -405,12 +405,12 @@ SELECT comp();
 -- query to exercise expand_tuple function
 CREATE TABLE t1 AS
 SELECT 1::int AS a , 2::int AS b
-FROM generate_series(1,20) q;
+FROM generate_series(1,200) q;
 
 ALTER TABLE t1 ADD COLUMN c text;
 
 SELECT a,
-       stddev(cast((SELECT sum(1) FROM generate_series(1,20) x) AS float4))
+       stddev(cast((SELECT sum(1) FROM generate_series(1,200) x) AS float4))
           OVER (PARTITION BY a,b,c ORDER BY b)
        AS z
 FROM t1;
diff --git a/src/test/regress/sql/foreign_key.sql b/src/test/regress/sql/foreign_key.sql
index ea08fd5a6f..81afcae802 100644
--- a/src/test/regress/sql/foreign_key.sql
+++ b/src/test/regress/sql/foreign_key.sql
@@ -1445,14 +1445,14 @@ create table other_partitioned_fk(a int, b int) partition by list (a);
 create table other_partitioned_fk_1 partition of other_partitioned_fk
   for values in (2048);
 insert into other_partitioned_fk
-  select 2048, x from generate_series(1,10) x;
+  select 2048, x from generate_series(1,100) x;
 -- this should fail
 alter table other_partitioned_fk add foreign key (a, b)
   references fk_notpartitioned_pk(a, b);
 -- add the missing keys and retry
 reset role;
 insert into fk_notpartitioned_pk (a, b)
-  select 2048, x from generate_series(1,10) x;
+  select 2048, x from generate_series(1,100) x;
 set role regress_other_partitioned_fk_owner;
 alter table other_partitioned_fk add foreign key (a, b)
   references fk_notpartitioned_pk(a, b);
diff --git a/src/test/regress/sql/groupingsets.sql b/src/test/regress/sql/groupingsets.sql
index 90ba27257a..3aa3c73602 100644
--- a/src/test/regress/sql/groupingsets.sql
+++ b/src/test/regress/sql/groupingsets.sql
@@ -45,7 +45,7 @@ create function gstest_data(v integer, out a integer, out b integer)
   returns setof record
   as $f$
     begin
-      return query select v, i from generate_series(1,3) i;
+      return query select v, i from generate_series(1,30) i;
     end;
   $f$ language plpgsql;
 
@@ -145,11 +145,11 @@ select a, d, grouping(a,b,c)
 -- even if they are equal()
 explain (costs off)
 select g as alias1, g as alias2
-  from generate_series(1,3) g
+  from generate_series(1,30) g
  group by alias1, rollup(alias2);
 
 select g as alias1, g as alias2
-  from generate_series(1,3) g
+  from generate_series(1,30) g
  group by alias1, rollup(alias2);
 
 -- check that pulled-up subquery outputs still go to null when appropriate
@@ -487,7 +487,7 @@ analyze bug_16784;
 alter table bug_16784 set (autovacuum_enabled = 'false');
 update pg_class set reltuples = 10 where relname='bug_16784';
 
-insert into bug_16784 select g/10, g from generate_series(1,40) g;
+insert into bug_16784 select g/10, g from generate_series(1,400) g;
 
 set work_mem='64kB';
 set enable_sort = false;
diff --git a/src/test/regress/sql/incremental_sort.sql b/src/test/regress/sql/incremental_sort.sql
index ab471bdfff..6288932da7 100644
--- a/src/test/regress/sql/incremental_sort.sql
+++ b/src/test/regress/sql/incremental_sort.sql
@@ -208,7 +208,7 @@ set parallel_tuple_cost = 0;
 set max_parallel_workers_per_gather = 2;
 
 create table t (a int, b int, c int);
-insert into t select mod(i,10),mod(i,10),i from generate_series(1,10000) s(i);
+insert into t select mod(i,10),mod(i,10),i from generate_series(1,100000) s(i);
 create index on t (a);
 analyze t;
 
diff --git a/src/test/regress/sql/index_including.sql b/src/test/regress/sql/index_including.sql
index 11c95974ec..fc9db6a5c7 100644
--- a/src/test/regress/sql/index_including.sql
+++ b/src/test/regress/sql/index_including.sql
@@ -7,7 +7,7 @@
 
 -- Regular index with included columns
 CREATE TABLE tbl_include_reg (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_reg SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_reg SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 CREATE INDEX tbl_include_reg_idx ON tbl_include_reg (c1, c2) INCLUDE (c3, c4);
 -- duplicate column is pretty pointless, but we allow it anyway
 CREATE INDEX ON tbl_include_reg (c1, c2) INCLUDE (c1, c3);
@@ -18,7 +18,7 @@ WHERE i.indrelid = 'tbl_include_reg'::regclass ORDER BY c.relname;
 
 -- Unique index and unique constraint
 CREATE TABLE tbl_include_unique1 (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_unique1 SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_unique1 SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 CREATE UNIQUE INDEX tbl_include_unique1_idx_unique ON tbl_include_unique1 using btree (c1, c2) INCLUDE (c3, c4);
 ALTER TABLE tbl_include_unique1 add UNIQUE USING INDEX tbl_include_unique1_idx_unique;
 ALTER TABLE tbl_include_unique1 add UNIQUE (c1, c2) INCLUDE (c3, c4);
@@ -28,20 +28,20 @@ WHERE i.indrelid = 'tbl_include_unique1'::regclass ORDER BY c.relname;
 
 -- Unique index and unique constraint. Both must fail.
 CREATE TABLE tbl_include_unique2 (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_unique2 SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_unique2 SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 CREATE UNIQUE INDEX tbl_include_unique2_idx_unique ON tbl_include_unique2 using btree (c1, c2) INCLUDE (c3, c4);
 ALTER TABLE tbl_include_unique2 add UNIQUE (c1, c2) INCLUDE (c3, c4);
 
 -- PK constraint
 CREATE TABLE tbl_include_pk (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_pk SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_pk SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 ALTER TABLE tbl_include_pk add PRIMARY KEY (c1, c2) INCLUDE (c3, c4);
 SELECT pg_get_indexdef(i.indexrelid)
 FROM pg_index i JOIN pg_class c ON i.indexrelid = c.oid
 WHERE i.indrelid = 'tbl_include_pk'::regclass ORDER BY c.relname;
 
 CREATE TABLE tbl_include_box (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_box SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_box SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 CREATE UNIQUE INDEX tbl_include_box_idx_unique ON tbl_include_box using btree (c1, c2) INCLUDE (c3, c4);
 ALTER TABLE tbl_include_box add PRIMARY KEY USING INDEX tbl_include_box_idx_unique;
 SELECT pg_get_indexdef(i.indexrelid)
@@ -50,7 +50,7 @@ WHERE i.indrelid = 'tbl_include_box'::regclass ORDER BY c.relname;
 
 -- PK constraint. Must fail.
 CREATE TABLE tbl_include_box_pk (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_box_pk SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_box_pk SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 ALTER TABLE tbl_include_box_pk add PRIMARY KEY (c1, c2) INCLUDE (c3, c4);
 
 
@@ -62,7 +62,7 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 DROP TABLE tbl;
 
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
@@ -70,9 +70,9 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,300) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
+INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
+INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,3000) AS x;
 explain (costs off)
 select * from tbl where (c1,c2,c3) < (2,5,1);
 select * from tbl where (c1,c2,c3) < (2,5,1);
@@ -89,7 +89,7 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
 DROP TABLE tbl;
 
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
@@ -97,9 +97,9 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
+INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
+INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,100) AS x;
 DROP TABLE tbl;
 
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
@@ -107,8 +107,8 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,100) AS x;
+INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,100) AS x;
 DROP TABLE tbl;
 
 /*
@@ -162,7 +162,7 @@ DROP TABLE tbl;
  * 4. CREATE INDEX CONCURRENTLY
  */
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box, UNIQUE(c1, c2) INCLUDE(c3,c4));
-INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,1000) AS x;
+INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10000) AS x;
 CREATE UNIQUE INDEX CONCURRENTLY on tbl (c1, c2) INCLUDE (c3, c4);
 SELECT indexdef FROM pg_indexes WHERE tablename = 'tbl' ORDER BY indexname;
 DROP TABLE tbl;
diff --git a/src/test/regress/sql/index_including_gist.sql b/src/test/regress/sql/index_including_gist.sql
index 7d5c99b2e7..b0ecab7042 100644
--- a/src/test/regress/sql/index_including_gist.sql
+++ b/src/test/regress/sql/index_including_gist.sql
@@ -5,7 +5,7 @@
 -- Regular index with included columns
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
 -- size is chosen to exceed page size and trigger actual truncation
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,8000) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,80000) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c2,c3);
 SELECT pg_get_indexdef(i.indexrelid)
 FROM pg_index i JOIN pg_class c ON i.indexrelid = c.oid
@@ -24,7 +24,7 @@ DROP TABLE tbl_gist;
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
 -- size is chosen to exceed page size and trigger actual truncation
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c2,c3);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,8000) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,80000) AS x;
 SELECT pg_get_indexdef(i.indexrelid)
 FROM pg_index i JOIN pg_class c ON i.indexrelid = c.oid
 WHERE i.indrelid = 'tbl_gist'::regclass ORDER BY c.relname;
@@ -38,7 +38,7 @@ DROP TABLE tbl_gist;
  * 2. CREATE INDEX CONCURRENTLY
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,100) AS x;
 CREATE INDEX CONCURRENTLY tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c2,c3);
 SELECT indexdef FROM pg_indexes WHERE tablename = 'tbl_gist' ORDER BY indexname;
 DROP TABLE tbl_gist;
@@ -48,7 +48,7 @@ DROP TABLE tbl_gist;
  * 3. REINDEX
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,100) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c3);
 SELECT indexdef FROM pg_indexes WHERE tablename = 'tbl_gist' ORDER BY indexname;
 REINDEX INDEX tbl_gist_idx;
@@ -61,7 +61,7 @@ DROP TABLE tbl_gist;
  * 4. Update, delete values in indexed table.
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,100) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c3);
 UPDATE tbl_gist SET c1 = 100 WHERE c1 = 2;
 UPDATE tbl_gist SET c1 = 1 WHERE c1 = 3;
@@ -72,7 +72,7 @@ DROP TABLE tbl_gist;
  * 5. Alter column type.
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,100) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c3);
 ALTER TABLE tbl_gist ALTER c1 TYPE bigint;
 ALTER TABLE tbl_gist ALTER c3 TYPE bigint;
@@ -83,8 +83,8 @@ DROP TABLE tbl_gist;
  * 6. EXCLUDE constraint.
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box, EXCLUDE USING gist (c4 WITH &&) INCLUDE (c1, c2, c3));
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(3*x,2*x),point(3*x+1,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,100) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(3*x,2*x),point(3*x+1,2*x+1)) FROM generate_series(1,100) AS x;
 EXPLAIN  (costs off) SELECT * FROM tbl_gist where c4 <@ box(point(1,1),point(10,10));
 \d tbl_gist
 DROP TABLE tbl_gist;
diff --git a/src/test/regress/sql/inherit.sql b/src/test/regress/sql/inherit.sql
index 572512cba0..d8d7fd4da5 100644
--- a/src/test/regress/sql/inherit.sql
+++ b/src/test/regress/sql/inherit.sql
@@ -100,7 +100,7 @@ INSERT INTO z VALUES (NULL, 'text'); -- should fail
 -- Check inherited UPDATE with first child excluded
 create table some_tab (f1 int, f2 int, f3 int, check (f1 < 10) no inherit);
 create table some_tab_child () inherits(some_tab);
-insert into some_tab_child select i, i+1, 0 from generate_series(1,1000) i;
+insert into some_tab_child select i, i+1, 0 from generate_series(1,10000) i;
 create index on some_tab_child(f1, f2);
 -- while at it, also check that statement-level triggers fire
 create function some_tab_stmt_trig_func() returns trigger as
@@ -724,7 +724,7 @@ reset enable_bitmapscan;
 create table inhpar(f1 int, f2 name);
 create table inhcld(f2 name, f1 int);
 alter table inhcld inherit inhpar;
-insert into inhpar select x, x::text from generate_series(1,5) x;
+insert into inhpar select x, x::text from generate_series(1,50) x;
 insert into inhcld select x::text, x from generate_series(6,10) x;
 
 explain (verbose, costs off)
@@ -742,7 +742,7 @@ create table inhcld1(f2 name, f1 int primary key);
 create table inhcld2(f1 int primary key, f2 name);
 alter table inhpar attach partition inhcld1 for values from (1) to (5);
 alter table inhpar attach partition inhcld2 for values from (5) to (100);
-insert into inhpar select x, x::text from generate_series(1,10) x;
+insert into inhpar select x, x::text from generate_series(1,100) x;
 
 explain (verbose, costs off)
 update inhpar i set (f1, f2) = (select i.f1, i.f2 || '-' from int4_tbl limit 1);
diff --git a/src/test/regress/sql/insert.sql b/src/test/regress/sql/insert.sql
index 2b086eeb6d..716b759a62 100644
--- a/src/test/regress/sql/insert.sql
+++ b/src/test/regress/sql/insert.sql
@@ -335,7 +335,7 @@ create table hpart1 partition of hash_parted for values with (modulus 4, remaind
 create table hpart2 partition of hash_parted for values with (modulus 4, remainder 2);
 create table hpart3 partition of hash_parted for values with (modulus 4, remainder 3);
 
-insert into hash_parted values(generate_series(1,10));
+insert into hash_parted values(generate_series(1,100));
 
 -- direct insert of values divisible by 4 - ok;
 insert into hpart0 values(12),(16);
diff --git a/src/test/regress/sql/join.sql b/src/test/regress/sql/join.sql
index dcc94c0715..a8cd6f582f 100644
--- a/src/test/regress/sql/join.sql
+++ b/src/test/regress/sql/join.sql
@@ -698,7 +698,7 @@ reset enable_nestloop;
 --
 
 create temp table tbl_ra(a int unique, b int);
-insert into tbl_ra select i, i%100 from generate_series(1,1000)i;
+insert into tbl_ra select i, i%100 from generate_series(1,10000)i;
 create index on tbl_ra (b);
 analyze tbl_ra;
 
diff --git a/src/test/regress/sql/json.sql b/src/test/regress/sql/json.sql
index 50b4ed6743..62a1d875f9 100644
--- a/src/test/regress/sql/json.sql
+++ b/src/test/regress/sql/json.sql
@@ -90,13 +90,13 @@ select * from pg_input_error_info('{"a":true', 'json');
 -- array_to_json
 
 SELECT array_to_json(array(select 1 as a));
-SELECT array_to_json(array_agg(q),false) from (select x as b, x * 2 as c from generate_series(1,3) x) q;
-SELECT array_to_json(array_agg(q),true) from (select x as b, x * 2 as c from generate_series(1,3) x) q;
+SELECT array_to_json(array_agg(q),false) from (select x as b, x * 2 as c from generate_series(1,30) x) q;
+SELECT array_to_json(array_agg(q),true) from (select x as b, x * 2 as c from generate_series(1,30) x) q;
 SELECT array_to_json(array_agg(q),false)
   FROM ( SELECT $$a$$ || x AS b, y AS c,
                ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-         FROM generate_series(1,2) x,
+         FROM generate_series(1,20) x,
               generate_series(4,5) y) q;
 SELECT array_to_json(array_agg(x),false) from generate_series(5,10) x;
 SELECT array_to_json('{{1,5},{99,100}}'::int[]);
@@ -122,7 +122,7 @@ FROM (SELECT $$a$$ || x AS b,
 
 CREATE TEMP TABLE rows AS
 SELECT x, 'txt' || x as y
-FROM generate_series(1,3) AS x;
+FROM generate_series(1,30) AS x;
 
 SELECT row_to_json(q,true)
 FROM rows q;
@@ -165,7 +165,7 @@ SELECT json_agg(q)
   FROM ( SELECT $$a$$ || x AS b, y AS c,
                ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-         FROM generate_series(1,2) x,
+         FROM generate_series(1,20) x,
               generate_series(4,5) y) q;
 
 SELECT json_agg(q ORDER BY x, y)
@@ -267,7 +267,7 @@ WHERE json_type = 'object';
 select count(*) from
     (select json_object_keys(json_object(array_agg(g)))
      from (select unnest(array['f'||n,n::text])as g
-           from generate_series(1,300) as n) x ) y;
+           from generate_series(1,3000) as n) x ) y;
 
 -- nulls
 
diff --git a/src/test/regress/sql/jsonb.sql b/src/test/regress/sql/jsonb.sql
index 97bc2242a1..1111bbcc0f 100644
--- a/src/test/regress/sql/jsonb.sql
+++ b/src/test/regress/sql/jsonb.sql
@@ -99,7 +99,7 @@ SELECT array_to_json(ARRAY [jsonb '{"a":1}', jsonb '{"b":[2,3]}']);
 
 CREATE TEMP TABLE rows AS
 SELECT x, 'txt' || x as y
-FROM generate_series(1,3) AS x;
+FROM generate_series(1,30) AS x;
 
 analyze rows;
 
diff --git a/src/test/regress/sql/limit.sql b/src/test/regress/sql/limit.sql
index 6f0cda9870..abd3a8d3b8 100644
--- a/src/test/regress/sql/limit.sql
+++ b/src/test/regress/sql/limit.sql
@@ -88,9 +88,9 @@ rollback;
 SELECT
   (SELECT n
      FROM (VALUES (1)) AS x,
-          (SELECT n FROM generate_series(1,10) AS n
+          (SELECT n FROM generate_series(1,100) AS n
              ORDER BY n LIMIT 1 OFFSET s-1) AS y) AS z
-  FROM generate_series(1,10) AS s;
+  FROM generate_series(1,100) AS s;
 
 --
 -- Test behavior of volatile and set-returning functions in conjunction
@@ -118,17 +118,17 @@ select unique1, unique2, nextval('testseq')
 select currval('testseq');
 
 explain (verbose, costs off)
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1,100)
   from tenk1 order by unique2 limit 7;
 
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1,100)
   from tenk1 order by unique2 limit 7;
 
 explain (verbose, costs off)
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1,100)
   from tenk1 order by tenthous limit 7;
 
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1,100)
   from tenk1 order by tenthous limit 7;
 
 -- use of random() is to keep planner from folding the expressions together
diff --git a/src/test/regress/sql/matview.sql b/src/test/regress/sql/matview.sql
index b74ee305e0..882174864b 100644
--- a/src/test/regress/sql/matview.sql
+++ b/src/test/regress/sql/matview.sql
@@ -201,7 +201,7 @@ refresh materialized view mvtest_error;  -- fail here
 drop materialized view mvtest_error;
 
 -- make sure that matview rows can be referenced as source rows (bug #9398)
-CREATE TABLE mvtest_v AS SELECT generate_series(1,10) AS a;
+CREATE TABLE mvtest_v AS SELECT generate_series(1,100) AS a;
 CREATE MATERIALIZED VIEW mvtest_mv_v AS SELECT a FROM mvtest_v WHERE a <= 5;
 DELETE FROM mvtest_v WHERE EXISTS ( SELECT * FROM mvtest_mv_v WHERE mvtest_mv_v.a = mvtest_v.a );
 SELECT * FROM mvtest_v;
diff --git a/src/test/regress/sql/multirangetypes.sql b/src/test/regress/sql/multirangetypes.sql
index 41d5524285..51e6c5c7eb 100644
--- a/src/test/regress/sql/multirangetypes.sql
+++ b/src/test/regress/sql/multirangetypes.sql
@@ -432,11 +432,11 @@ SELECT '{[1,4), [7,10)}'::nummultirange * '{[0,2), [3,8), [9,12)}'::nummultirang
 
 -- test GiST index
 create table test_multirange_gist(mr int4multirange);
-insert into test_multirange_gist select int4multirange(int4range(g, g+10),int4range(g+20, g+30),int4range(g+40, g+50)) from generate_series(1,2000) g;
-insert into test_multirange_gist select '{}'::int4multirange from generate_series(1,500) g;
-insert into test_multirange_gist select int4multirange(int4range(g, g+10000)) from generate_series(1,1000) g;
-insert into test_multirange_gist select int4multirange(int4range(NULL, g*10, '(]'), int4range(g*10, g*20, '(]')) from generate_series(1,100) g;
-insert into test_multirange_gist select int4multirange(int4range(g*10, g*20, '(]'), int4range(g*20, NULL, '(]')) from generate_series(1,100) g;
+insert into test_multirange_gist select int4multirange(int4range(g, g+10),int4range(g+20, g+30),int4range(g+40, g+50)) from generate_series(1,20000) g;
+insert into test_multirange_gist select '{}'::int4multirange from generate_series(1,5000) g;
+insert into test_multirange_gist select int4multirange(int4range(g, g+10000)) from generate_series(1,10000) g;
+insert into test_multirange_gist select int4multirange(int4range(NULL, g*10, '(]'), int4range(g*10, g*20, '(]')) from generate_series(1,1000) g;
+insert into test_multirange_gist select int4multirange(int4range(g*10, g*20, '(]'), int4range(g*20, NULL, '(]')) from generate_series(1,1000) g;
 create index test_mulrirange_gist_idx on test_multirange_gist using gist (mr);
 
 -- test statistics and selectivity estimation as well
diff --git a/src/test/regress/sql/partition_join.sql b/src/test/regress/sql/partition_join.sql
index afadefd50f..ad8383c742 100644
--- a/src/test/regress/sql/partition_join.sql
+++ b/src/test/regress/sql/partition_join.sql
@@ -531,9 +531,9 @@ create temp table prtx2_1 partition of prtx2 for values from (1) to (11);
 create temp table prtx2_2 partition of prtx2 for values from (11) to (21);
 create temp table prtx2_3 partition of prtx2 for values from (21) to (31);
 insert into prtx1 select 1 + i%30, i, i
-  from generate_series(1,1000) i;
+  from generate_series(1,10000) i;
 insert into prtx2 select 1 + i%30, i, i
-  from generate_series(1,500) i, generate_series(1,10) j;
+  from generate_series(1,5000) i, generate_series(1,100) j;
 create index on prtx2 (b);
 create index on prtx2 (c);
 analyze prtx1;
diff --git a/src/test/regress/sql/partition_prune.sql b/src/test/regress/sql/partition_prune.sql
index 63f1bb5de9..f9b7532a9e 100644
--- a/src/test/regress/sql/partition_prune.sql
+++ b/src/test/regress/sql/partition_prune.sql
@@ -512,7 +512,7 @@ create table list_part2 partition of list_part for values in (2);
 create table list_part3 partition of list_part for values in (3);
 create table list_part4 partition of list_part for values in (4);
 
-insert into list_part select generate_series(1,4);
+insert into list_part select generate_series(1,40);
 
 begin;
 
@@ -601,7 +601,7 @@ select explain_parallel_append('select count(*) from ab where (a = (select 1) or
 -- Test pruning during parallel nested loop query
 create table lprt_a (a int not null);
 -- Insert some values we won't find in ab
-insert into lprt_a select 0 from generate_series(1,100);
+insert into lprt_a select 0 from generate_series(1,1000);
 
 -- and insert some values that we should find.
 insert into lprt_a values(1),(1);
diff --git a/src/test/regress/sql/plancache.sql b/src/test/regress/sql/plancache.sql
index 4b2f11dcc6..c6e7f37e0c 100644
--- a/src/test/regress/sql/plancache.sql
+++ b/src/test/regress/sql/plancache.sql
@@ -147,7 +147,7 @@ create function cachebug() returns void as $$
 declare r int;
 begin
   drop table if exists temptable cascade;
-  create temp table temptable as select * from generate_series(1,3) as f1;
+  create temp table temptable as select * from generate_series(1,30) as f1;
   create temp view vv as select * from temptable;
   for r in select * from vv loop
     raise notice '%', r;
@@ -181,7 +181,7 @@ deallocate pstmt_def_insert;
 -- Test plan_cache_mode
 
 create table test_mode (a int);
-insert into test_mode select 1 from generate_series(1,1000) union all select 2;
+insert into test_mode select 1 from generate_series(1,10000) union all select 2;
 create index on test_mode (a);
 analyze test_mode;
 
diff --git a/src/test/regress/sql/plpgsql.sql b/src/test/regress/sql/plpgsql.sql
index 18c91572ae..b77a5b4ee7 100644
--- a/src/test/regress/sql/plpgsql.sql
+++ b/src/test/regress/sql/plpgsql.sql
@@ -2623,7 +2623,7 @@ set plpgsql.extra_warnings to 'too_many_rows';
 do $$
 declare x int;
 begin
-  select v from generate_series(1,2) g(v) into x;
+  select v from generate_series(1,20) g(v) into x;
 end;
 $$;
 
@@ -2632,7 +2632,7 @@ set plpgsql.extra_errors to 'too_many_rows';
 do $$
 declare x int;
 begin
-  select v from generate_series(1,2) g(v) into x;
+  select v from generate_series(1,20) g(v) into x;
 end;
 $$;
 
diff --git a/src/test/regress/sql/polymorphism.sql b/src/test/regress/sql/polymorphism.sql
index fa57db6559..b189a5864e 100644
--- a/src/test/regress/sql/polymorphism.sql
+++ b/src/test/regress/sql/polymorphism.sql
@@ -638,10 +638,10 @@ create aggregate first_el_agg_any(anyelement) (
   FINALFUNC = first_el
 );
 
-select first_el_agg_f8(x::float8) from generate_series(1,10) x;
-select first_el_agg_any(x) from generate_series(1,10) x;
-select first_el_agg_f8(x::float8) over(order by x) from generate_series(1,10) x;
-select first_el_agg_any(x) over(order by x) from generate_series(1,10) x;
+select first_el_agg_f8(x::float8) from generate_series(1,100) x;
+select first_el_agg_any(x) from generate_series(1,100) x;
+select first_el_agg_f8(x::float8) over(order by x) from generate_series(1,100) x;
+select first_el_agg_any(x) over(order by x) from generate_series(1,100) x;
 
 -- check that we can apply functions taking ANYARRAY to pg_stats
 select distinct array_ndims(histogram_bounds) from pg_stats
diff --git a/src/test/regress/sql/portals.sql b/src/test/regress/sql/portals.sql
index fc4cccb96c..126f18c110 100644
--- a/src/test/regress/sql/portals.sql
+++ b/src/test/regress/sql/portals.sql
@@ -525,7 +525,7 @@ BEGIN;
 CREATE TABLE current_check (currentid int, payload text);
 CREATE TABLE current_check_1 () INHERITS (current_check);
 CREATE TABLE current_check_2 () INHERITS (current_check);
-INSERT INTO current_check_1 SELECT i, 'p' || i FROM generate_series(1,9) i;
+INSERT INTO current_check_1 SELECT i, 'p' || i FROM generate_series(1,90) i;
 INSERT INTO current_check_2 SELECT i, 'P' || i FROM generate_series(10,19) i;
 
 DECLARE c1 SCROLL CURSOR FOR SELECT * FROM current_check;
@@ -575,9 +575,9 @@ fetch all in c1;
 fetch backward all in c1;
 rollback;
 begin;
-explain (costs off) declare c2 cursor for select generate_series(1,3) as g;
-explain (costs off) declare c2 scroll cursor for select generate_series(1,3) as g;
-declare c2 scroll cursor for select generate_series(1,3) as g;
+explain (costs off) declare c2 cursor for select generate_series(1,30) as g;
+explain (costs off) declare c2 scroll cursor for select generate_series(1,30) as g;
+declare c2 scroll cursor for select generate_series(1,30) as g;
 fetch all in c2;
 fetch backward all in c2;
 rollback;
diff --git a/src/test/regress/sql/privileges.sql b/src/test/regress/sql/privileges.sql
index b7e1cb6cdd..31fd902380 100644
--- a/src/test/regress/sql/privileges.sql
+++ b/src/test/regress/sql/privileges.sql
@@ -308,7 +308,7 @@ SELECT * FROM atest1; -- ok
 SET SESSION AUTHORIZATION regress_priv_user1;
 
 CREATE TABLE atest12 as
-  SELECT x AS a, 10001 - x AS b FROM generate_series(1,10000) x;
+  SELECT x AS a, 10001 - x AS b FROM generate_series(1,100000) x;
 CREATE INDEX ON atest12 (a);
 CREATE INDEX ON atest12 (abs(a));
 -- results below depend on having quite accurate stats for atest12, so...
diff --git a/src/test/regress/sql/psql_crosstab.sql b/src/test/regress/sql/psql_crosstab.sql
index 5a4511389d..617c441b05 100644
--- a/src/test/regress/sql/psql_crosstab.sql
+++ b/src/test/regress/sql/psql_crosstab.sql
@@ -104,7 +104,7 @@ SELECT v,h,i,c FROM ctv_data
  \crosstabview 2 h 4
 
 -- error: too many columns
-SELECT a,a,1 FROM generate_series(1,3000) AS a
+SELECT a,a,1 FROM generate_series(1,30000) AS a
  \crosstabview
 
 -- error: only one column
@@ -115,7 +115,7 @@ DROP TABLE ctv_data;
 -- check error reporting (bug #14476)
 CREATE TABLE ctv_data (x int, y int, v text);
 
-INSERT INTO ctv_data SELECT 1, x, '*' || x FROM generate_series(1,10) x;
+INSERT INTO ctv_data SELECT 1, x, '*' || x FROM generate_series(1,100) x;
 SELECT * FROM ctv_data \crosstabview
 
 INSERT INTO ctv_data VALUES (1, 10, '*'); -- duplicate data to cause error
diff --git a/src/test/regress/sql/publication.sql b/src/test/regress/sql/publication.sql
index 479d4f3264..9022e05e7b 100644
--- a/src/test/regress/sql/publication.sql
+++ b/src/test/regress/sql/publication.sql
@@ -237,7 +237,7 @@ CREATE PUBLICATION testpub6 FOR TABLE rf_bug WHERE (status = 'open') WITH (publi
 DROP TABLE rf_bug;
 DROP TYPE rf_bug_status;
 -- fail - row filter expression is not simple
-CREATE PUBLICATION testpub6 FOR TABLE testpub_rf_tbl1 WHERE (a IN (SELECT generate_series(1,5)));
+CREATE PUBLICATION testpub6 FOR TABLE testpub_rf_tbl1 WHERE (a IN (SELECT generate_series(1,50)));
 -- fail - system columns are not allowed
 CREATE PUBLICATION testpub6 FOR TABLE testpub_rf_tbl1 WHERE ('(0,1)'::tid = ctid);
 -- ok - conditional expressions are allowed
diff --git a/src/test/regress/sql/rangefuncs.sql b/src/test/regress/sql/rangefuncs.sql
index 3c47c98e11..c25cf2e810 100644
--- a/src/test/regress/sql/rangefuncs.sql
+++ b/src/test/regress/sql/rangefuncs.sql
@@ -41,14 +41,14 @@ create temporary view vw_ord as select * from rows from(unnest(array[10,20],arra
 select * from vw_ord;
 select definition from pg_views where viewname='vw_ord';
 drop view vw_ord;
-create temporary view vw_ord as select * from rows from(unnest(array[10,20],array['foo','bar']), generate_series(1,2)) as z(a,b,c);
+create temporary view vw_ord as select * from rows from(unnest(array[10,20],array['foo','bar']), generate_series(1,20)) as z(a,b,c);
 select * from vw_ord;
 select definition from pg_views where viewname='vw_ord';
 drop view vw_ord;
 
 -- ordinality and multiple functions vs. rewind and reverse scan
 begin;
-declare rf_cur scroll cursor for select * from rows from(generate_series(1,5),generate_series(1,2)) with ordinality as g(i,j,o);
+declare rf_cur scroll cursor for select * from rows from(generate_series(1,50),generate_series(1,20)) with ordinality as g(i,j,o);
 fetch all from rf_cur;
 fetch backward all from rf_cur;
 fetch all from rf_cur;
@@ -296,7 +296,7 @@ SELECT setval('rngfunc_rescan_seq1',1,false),setval('rngfunc_rescan_seq2',1,fals
 SELECT * FROM (VALUES (1),(2),(3)) v(r), ROWS FROM( rngfunc_sql(10+r,13), rngfunc_mat(10+r,13) );
 
 SELECT setval('rngfunc_rescan_seq1',1,false),setval('rngfunc_rescan_seq2',1,false);
-SELECT * FROM generate_series(1,2) r1, generate_series(r1,3) r2, ROWS FROM( rngfunc_sql(10+r1,13), rngfunc_mat(10+r2,13) );
+SELECT * FROM generate_series(1,20) r1, generate_series(r1,3) r2, ROWS FROM( rngfunc_sql(10+r1,13), rngfunc_mat(10+r2,13) );
 
 SELECT * FROM (VALUES (1),(2),(3)) v(r), generate_series(10+r,20-r) f(i);
 SELECT * FROM (VALUES (1),(2),(3)) v(r), generate_series(10+r,20-r) WITH ORDINALITY AS f(i,o);
@@ -434,7 +434,7 @@ AS 'select $1, array[$1,$1]' LANGUAGE sql;
 
 CREATE OR REPLACE FUNCTION rngfunc()
 RETURNS TABLE(a int)
-AS $$ SELECT a FROM generate_series(1,5) a(a) $$ LANGUAGE sql;
+AS $$ SELECT a FROM generate_series(1,50) a(a) $$ LANGUAGE sql;
 SELECT * FROM rngfunc();
 DROP FUNCTION rngfunc();
 
diff --git a/src/test/regress/sql/rangetypes.sql b/src/test/regress/sql/rangetypes.sql
index a5ecdf5372..cbf5d34fcd 100644
--- a/src/test/regress/sql/rangetypes.sql
+++ b/src/test/regress/sql/rangetypes.sql
@@ -219,13 +219,13 @@ select daterange('2000-01-01'::date, 'infinity'::date, '[]');
 create table test_range_gist(ir int4range);
 create index test_range_gist_idx on test_range_gist using gist (ir);
 
-insert into test_range_gist select int4range(g, g+10) from generate_series(1,2000) g;
-insert into test_range_gist select 'empty'::int4range from generate_series(1,500) g;
-insert into test_range_gist select int4range(g, g+10000) from generate_series(1,1000) g;
-insert into test_range_gist select 'empty'::int4range from generate_series(1,500) g;
-insert into test_range_gist select int4range(NULL,g*10,'(]') from generate_series(1,100) g;
-insert into test_range_gist select int4range(g*10,NULL,'(]') from generate_series(1,100) g;
-insert into test_range_gist select int4range(g, g+10) from generate_series(1,2000) g;
+insert into test_range_gist select int4range(g, g+10) from generate_series(1,20000) g;
+insert into test_range_gist select 'empty'::int4range from generate_series(1,5000) g;
+insert into test_range_gist select int4range(g, g+10000) from generate_series(1,10000) g;
+insert into test_range_gist select 'empty'::int4range from generate_series(1,5000) g;
+insert into test_range_gist select int4range(NULL,g*10,'(]') from generate_series(1,1000) g;
+insert into test_range_gist select int4range(g*10,NULL,'(]') from generate_series(1,1000) g;
+insert into test_range_gist select int4range(g, g+10) from generate_series(1,20000) g;
 
 -- test statistics and selectivity estimation as well
 --
@@ -384,7 +384,7 @@ RESET enable_bitmapscan;
 -- test elem <@ range operator
 create table test_range_elem(i int4);
 create index test_range_elem_idx on test_range_elem (i);
-insert into test_range_elem select i from generate_series(1,100) i;
+insert into test_range_elem select i from generate_series(1,1000) i;
 
 SET enable_seqscan    = f;
 
diff --git a/src/test/regress/sql/rowtypes.sql b/src/test/regress/sql/rowtypes.sql
index 174b062144..c996d442e6 100644
--- a/src/test/regress/sql/rowtypes.sql
+++ b/src/test/regress/sql/rowtypes.sql
@@ -165,7 +165,7 @@ order by thousand, hundred;
 -- Test case for bug #14010: indexed row comparisons fail with nulls
 create temp table test_table (a text, b text);
 insert into test_table values ('a', 'b');
-insert into test_table select 'a', null from generate_series(1,1000);
+insert into test_table select 'a', null from generate_series(1,10000);
 insert into test_table values ('b', 'a');
 create index on test_table (a,b);
 set enable_sort = off;
diff --git a/src/test/regress/sql/select_into.sql b/src/test/regress/sql/select_into.sql
index 689c448cc2..ef142d5318 100644
--- a/src/test/regress/sql/select_into.sql
+++ b/src/test/regress/sql/select_into.sql
@@ -28,19 +28,19 @@ GRANT ALL ON SCHEMA selinto_schema TO public;
 SET SESSION AUTHORIZATION regress_selinto_user;
 -- WITH DATA, passes.
 CREATE TABLE selinto_schema.tbl_withdata1 (a)
-  AS SELECT generate_series(1,3) WITH DATA;
+  AS SELECT generate_series(1,30) WITH DATA;
 INSERT INTO selinto_schema.tbl_withdata1 VALUES (4);
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
   CREATE TABLE selinto_schema.tbl_withdata2 (a) AS
-  SELECT generate_series(1,3) WITH DATA;
+  SELECT generate_series(1,30) WITH DATA;
 -- WITH NO DATA, passes.
 CREATE TABLE selinto_schema.tbl_nodata1 (a) AS
-  SELECT generate_series(1,3) WITH NO DATA;
+  SELECT generate_series(1,30) WITH NO DATA;
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
   CREATE TABLE selinto_schema.tbl_nodata2 (a) AS
-  SELECT generate_series(1,3) WITH NO DATA;
+  SELECT generate_series(1,30) WITH NO DATA;
 -- EXECUTE and WITH DATA, passes.
-PREPARE data_sel AS SELECT generate_series(1,3);
+PREPARE data_sel AS SELECT generate_series(1,30);
 CREATE TABLE selinto_schema.tbl_withdata3 (a) AS
   EXECUTE data_sel WITH DATA;
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
diff --git a/src/test/regress/sql/select_parallel.sql b/src/test/regress/sql/select_parallel.sql
index 3e4bfcb71f..ee8f685439 100644
--- a/src/test/regress/sql/select_parallel.sql
+++ b/src/test/regress/sql/select_parallel.sql
@@ -216,7 +216,7 @@ explain (costs off)
 select count(*) from tenk1, tenk2 where tenk1.hundred > 1 and tenk2.thousand=0;
 
 create table bmscantest (a int, t text);
-insert into bmscantest select r, 'fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo' FROM generate_series(1,100000) r;
+insert into bmscantest select r, 'fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo' FROM generate_series(1,1000000) r;
 create index i_bmtest ON bmscantest(a);
 select count(*) from bmscantest where a>1;
 
diff --git a/src/test/regress/sql/spgist.sql b/src/test/regress/sql/spgist.sql
index 4828ede68c..910b4be73b 100644
--- a/src/test/regress/sql/spgist.sql
+++ b/src/test/regress/sql/spgist.sql
@@ -39,7 +39,7 @@ insert into spgist_box_tbl(b)
 select box(point(i,j),point(i+s,j+s))
   from generate_series(1,100,5) i,
        generate_series(1,100,5) j,
-       generate_series(1,10) s;
+       generate_series(1,100) s;
 create index spgist_box_idx on spgist_box_tbl using spgist (b);
 
 select count(*)
diff --git a/src/test/regress/sql/sqljson.sql b/src/test/regress/sql/sqljson.sql
index 343d344d27..3d41e49805 100644
--- a/src/test/regress/sql/sqljson.sql
+++ b/src/test/regress/sql/sqljson.sql
@@ -344,15 +344,15 @@ DROP VIEW json_array_view;
 -- Test JSON_OBJECTAGG deparsing
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1,50) i;
 
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING text) OVER (PARTITION BY i % 2)
-FROM generate_series(1,5) i;
+FROM generate_series(1,50) i;
 
 CREATE VIEW json_objectagg_view AS
 SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1,50) i;
 
 \sv json_objectagg_view
 
@@ -361,15 +361,15 @@ DROP VIEW json_objectagg_view;
 -- Test JSON_ARRAYAGG deparsing
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1,50) i;
 
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING text) OVER (PARTITION BY i % 2)
-FROM generate_series(1,5) i;
+FROM generate_series(1,50) i;
 
 CREATE VIEW json_arrayagg_view AS
 SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1,50) i;
 
 \sv json_arrayagg_view
 
diff --git a/src/test/regress/sql/stats.sql b/src/test/regress/sql/stats.sql
index ed0bc1ef07..c75c1f1c9b 100644
--- a/src/test/regress/sql/stats.sql
+++ b/src/test/regress/sql/stats.sql
@@ -547,7 +547,7 @@ SELECT pg_stat_have_stats('database', :dboid, 1);
 SELECT pg_stat_have_stats('database', :dboid, 0);
 
 -- pg_stat_have_stats returns true for committed index creation
-CREATE table stats_test_tab1 as select generate_series(1,10) a;
+CREATE table stats_test_tab1 as select generate_series(1,100) a;
 CREATE index stats_test_idx1 on stats_test_tab1(a);
 SELECT 'stats_test_idx1'::regclass::oid AS stats_test_idx1_oid \gset
 SET enable_seqscan TO off;
@@ -613,7 +613,7 @@ SELECT sum(writes) AS writes, sum(fsyncs) AS fsyncs
   FROM pg_stat_io
   WHERE object = 'relation' \gset io_sum_shared_before_
 CREATE TABLE test_io_shared(a int);
-INSERT INTO test_io_shared SELECT i FROM generate_series(1,100)i;
+INSERT INTO test_io_shared SELECT i FROM generate_series(1,1000)i;
 SELECT pg_stat_force_next_flush();
 SELECT sum(extends) AS io_sum_shared_after_extends
   FROM pg_stat_io WHERE context = 'normal' AND object = 'relation' \gset
@@ -752,7 +752,7 @@ RESET wal_skip_threshold;
 -- BufferAccessStrategy, are tracked in pg_stat_io.
 SELECT sum(extends) AS io_sum_bulkwrite_strategy_extends_before
   FROM pg_stat_io WHERE context = 'bulkwrite' \gset
-CREATE TABLE test_io_bulkwrite_strategy AS SELECT i FROM generate_series(1,100)i;
+CREATE TABLE test_io_bulkwrite_strategy AS SELECT i FROM generate_series(1,1000)i;
 SELECT pg_stat_force_next_flush();
 SELECT sum(extends) AS io_sum_bulkwrite_strategy_extends_after
   FROM pg_stat_io WHERE context = 'bulkwrite' \gset
@@ -859,7 +859,7 @@ CREATE TABLE table_fillfactor (
 ) with (fillfactor=10, autovacuum_enabled=off);
 
 INSERT INTO table_fillfactor
-SELECT 'x' FROM generate_series(1,1000);
+SELECT 'x' FROM generate_series(1,10000);
 
 SELECT * FROM check_estimated_rows('SELECT * FROM table_fillfactor');
 
diff --git a/src/test/regress/sql/stats_ext.sql b/src/test/regress/sql/stats_ext.sql
index 0c08a6cc42..b20d0c4b58 100644
--- a/src/test/regress/sql/stats_ext.sql
+++ b/src/test/regress/sql/stats_ext.sql
@@ -235,7 +235,7 @@ WITH (autovacuum_enabled = off);
 -- over-estimates when using only per-column statistics
 INSERT INTO ndistinct (a, b, c, filler1)
      SELECT i/100, i/100, i/100, (i/100) || ' dollars and zero cents'
-       FROM generate_series(1,1000) s(i);
+       FROM generate_series(1,10000) s(i);
 
 ANALYZE ndistinct;
 
diff --git a/src/test/regress/sql/subselect.sql b/src/test/regress/sql/subselect.sql
index e5a562c3f5..9fe6e4859c 100644
--- a/src/test/regress/sql/subselect.sql
+++ b/src/test/regress/sql/subselect.sql
@@ -140,7 +140,7 @@ from int8_tbl group by q1 order by q1;
 -- Unspecified-type literals in output columns should resolve as text
 
 SELECT *, pg_typeof(f1) FROM
-  (SELECT 'foo' AS f1 FROM generate_series(1,3)) ss ORDER BY 1;
+  (SELECT 'foo' AS f1 FROM generate_series(1,30)) ss ORDER BY 1;
 
 -- ... unless there's context to suggest differently
 
@@ -702,7 +702,7 @@ select exists(select * from nocolumns);
 -- Check behavior with a SubPlan in VALUES (bug #14924)
 --
 select val.x
-  from generate_series(1,10) as s(i),
+  from generate_series(1,100) as s(i),
   lateral (
     values ((select s.i + 1)), (s.i + 101)
   ) as val(x)
@@ -738,9 +738,9 @@ select * from int4_tbl where
 --
 explain (verbose, costs off)
 select * from int4_tbl o where (f1, f1) in
-  (select f1, generate_series(1,50) / 10 g from int4_tbl i group by f1);
+  (select f1, generate_series(1,500) / 10 g from int4_tbl i group by f1);
 select * from int4_tbl o where (f1, f1) in
-  (select f1, generate_series(1,50) / 10 g from int4_tbl i group by f1);
+  (select f1, generate_series(1,500) / 10 g from int4_tbl i group by f1);
 
 --
 -- check for over-optimization of whole-row Var referencing an Append plan
@@ -882,7 +882,7 @@ drop table sq_limit;
 begin;
 
 declare c1 scroll cursor for
- select * from generate_series(1,4) i
+ select * from generate_series(1,40) i
   where i <> all (values (2),(3));
 
 move forward all in c1;
diff --git a/src/test/regress/sql/text.sql b/src/test/regress/sql/text.sql
index 540e551254..3b20bdfed6 100644
--- a/src/test/regress/sql/text.sql
+++ b/src/test/regress/sql/text.sql
@@ -93,7 +93,7 @@ select format('%2$s, %1$s', variadic array[1, 2]);
 select format('Hello', variadic NULL::int[]);
 -- variadic argument allows simulating more than FUNC_MAX_ARGS parameters
 select format(string_agg('%s',','), variadic array_agg(i))
-from generate_series(1,200) g(i);
+from generate_series(1,2000) g(i);
 -- check field widths and left, right alignment
 select format('>>%10s<<', 'Hello');
 select format('>>%10s<<', NULL);
diff --git a/src/test/regress/sql/tidrangescan.sql b/src/test/regress/sql/tidrangescan.sql
index ac09ebb626..08f1c69196 100644
--- a/src/test/regress/sql/tidrangescan.sql
+++ b/src/test/regress/sql/tidrangescan.sql
@@ -13,7 +13,7 @@ SELECT ctid FROM tidrangescan WHERE ctid > '(9, 0)';
 SELECT ctid FROM tidrangescan WHERE ctid > '(9, 0)';
 
 -- insert enough tuples to fill at least two pages
-INSERT INTO tidrangescan SELECT i,repeat('x', 100) FROM generate_series(1,200) AS s(i);
+INSERT INTO tidrangescan SELECT i,repeat('x', 100) FROM generate_series(1,2000) AS s(i);
 
 -- remove all tuples after the 10th tuple on each page.  Trying to ensure
 -- we get the same layout with all CPU architectures and smaller than standard
diff --git a/src/test/regress/sql/tsrf.sql b/src/test/regress/sql/tsrf.sql
index 7c22529a0d..a9a512f68b 100644
--- a/src/test/regress/sql/tsrf.sql
+++ b/src/test/regress/sql/tsrf.sql
@@ -9,7 +9,7 @@ SELECT generate_series(1, 3);
 SELECT generate_series(1, 3), generate_series(3,5);
 
 -- parallel iteration, different number of rows
-SELECT generate_series(1, 2), generate_series(1,4);
+SELECT generate_series(1, 20), generate_series(1,40);
 
 -- srf, with SRF argument
 SELECT generate_series(1, generate_series(1, 3));
@@ -18,7 +18,7 @@ SELECT generate_series(1, generate_series(1, 3));
 SELECT * FROM generate_series(1, generate_series(1, 3));
 
 -- srf, with two SRF arguments
-SELECT generate_series(generate_series(1,3), generate_series(2, 4));
+SELECT generate_series(generate_series(1,30), generate_series(2, 40));
 
 -- check proper nesting of SRFs in different expressions
 explain (verbose, costs off)
@@ -41,14 +41,14 @@ SELECT * FROM few f1,
   (SELECT unnest(ARRAY[1,2]) FROM few f2 WHERE false OFFSET 0) ss;
 
 -- SRF output order of sorting is maintained, if SRF is not referenced
-SELECT few.id, generate_series(1,3) g FROM few ORDER BY id DESC;
+SELECT few.id, generate_series(1,30) g FROM few ORDER BY id DESC;
 
 -- but SRFs can be referenced in sort
-SELECT few.id, generate_series(1,3) g FROM few ORDER BY id, g DESC;
-SELECT few.id, generate_series(1,3) g FROM few ORDER BY id, generate_series(1,3) DESC;
+SELECT few.id, generate_series(1,30) g FROM few ORDER BY id, g DESC;
+SELECT few.id, generate_series(1,30) g FROM few ORDER BY id, generate_series(1,30) DESC;
 
 -- it's weird to have ORDER BYs that increase the number of results
-SELECT few.id FROM few ORDER BY id, generate_series(1,3) DESC;
+SELECT few.id FROM few ORDER BY id, generate_series(1,30) DESC;
 
 -- SRFs are computed after aggregation
 SET enable_hashagg TO 0; -- stable output order
@@ -59,31 +59,31 @@ SELECT few.dataa, count(*), min(id), max(id), unnest('{1,1,3}'::int[]) FROM few
 RESET enable_hashagg;
 
 -- check HAVING works when GROUP BY does [not] reference SRF output
-SELECT dataa, generate_series(1,1), count(*) FROM few GROUP BY 1 HAVING count(*) > 1;
-SELECT dataa, generate_series(1,1), count(*) FROM few GROUP BY 1, 2 HAVING count(*) > 1;
+SELECT dataa, generate_series(1,10), count(*) FROM few GROUP BY 1 HAVING count(*) > 1;
+SELECT dataa, generate_series(1,10), count(*) FROM few GROUP BY 1, 2 HAVING count(*) > 1;
 
 -- it's weird to have GROUP BYs that increase the number of results
 SELECT few.dataa, count(*) FROM few WHERE dataa = 'a' GROUP BY few.dataa ORDER BY 2;
 SELECT few.dataa, count(*) FROM few WHERE dataa = 'a' GROUP BY few.dataa, unnest('{1,1,3}'::int[]) ORDER BY 2;
 
 -- SRFs are not allowed if they'd need to be conditionally executed
-SELECT q1, case when q1 > 0 then generate_series(1,3) else 0 end FROM int8_tbl;
-SELECT q1, coalesce(generate_series(1,3), 0) FROM int8_tbl;
+SELECT q1, case when q1 > 0 then generate_series(1,30) else 0 end FROM int8_tbl;
+SELECT q1, coalesce(generate_series(1,30), 0) FROM int8_tbl;
 
 -- SRFs are not allowed in aggregate arguments
 SELECT min(generate_series(1, 3)) FROM few;
 
 -- ... unless they're within a sub-select
-SELECT sum((3 = ANY(SELECT generate_series(1,4)))::int);
+SELECT sum((3 = ANY(SELECT generate_series(1,40)))::int);
 
 SELECT sum((3 = ANY(SELECT lag(x) over(order by x)
-                    FROM generate_series(1,4) x))::int);
+                    FROM generate_series(1,40) x))::int);
 
 -- SRFs are not allowed in window function arguments, either
 SELECT min(generate_series(1, 3)) OVER() FROM few;
 
 -- SRFs are normally computed after window functions
-SELECT id,lag(id) OVER(), count(*) OVER(), generate_series(1,3) FROM few;
+SELECT id,lag(id) OVER(), count(*) OVER(), generate_series(1,30) FROM few;
 -- unless referencing SRFs
 SELECT SUM(count(*)) OVER(PARTITION BY generate_series(1,3) ORDER BY generate_series(1,3)), generate_series(1,3) g FROM few GROUP BY g;
 
diff --git a/src/test/regress/sql/union.sql b/src/test/regress/sql/union.sql
index f8826514e4..aa9f4c45be 100644
--- a/src/test/regress/sql/union.sql
+++ b/src/test/regress/sql/union.sql
@@ -312,10 +312,10 @@ set enable_sort = false;
 -- fine to make use of Unique, which is cheaper than HashAggregate and we've
 -- no means to disable Unique.
 explain (costs off)
-select from generate_series(1,5) intersect select from generate_series(1,3);
+select from generate_series(1,50) intersect select from generate_series(1,30);
 
 select from generate_series(1,5) union all select from generate_series(1,3);
-select from generate_series(1,5) intersect select from generate_series(1,3);
+select from generate_series(1,50) intersect select from generate_series(1,30);
 select from generate_series(1,5) intersect all select from generate_series(1,3);
 select from generate_series(1,5) except select from generate_series(1,3);
 select from generate_series(1,5) except all select from generate_series(1,3);
@@ -327,11 +327,11 @@ set enable_sort = true;
 explain (costs off)
 select from generate_series(1,5) union select from generate_series(1,3);
 explain (costs off)
-select from generate_series(1,5) intersect select from generate_series(1,3);
+select from generate_series(1,50) intersect select from generate_series(1,30);
 
 select from generate_series(1,5) union select from generate_series(1,3);
 select from generate_series(1,5) union all select from generate_series(1,3);
-select from generate_series(1,5) intersect select from generate_series(1,3);
+select from generate_series(1,50) intersect select from generate_series(1,30);
 select from generate_series(1,5) intersect all select from generate_series(1,3);
 select from generate_series(1,5) except select from generate_series(1,3);
 select from generate_series(1,5) except all select from generate_series(1,3);
diff --git a/src/test/regress/sql/updatable_views.sql b/src/test/regress/sql/updatable_views.sql
index 93b693ae83..c1dc2ac582 100644
--- a/src/test/regress/sql/updatable_views.sql
+++ b/src/test/regress/sql/updatable_views.sql
@@ -203,17 +203,17 @@ MERGE INTO rw_view1 t USING (VALUES (5, 'X')) AS v(a,b) ON t.a = v.a
 
 EXPLAIN (costs off)
 MERGE INTO rw_view1 t
-  USING (SELECT * FROM generate_series(1,5)) AS s(a) ON t.a = s.a
+  USING (SELECT * FROM generate_series(1,50)) AS s(a) ON t.a = s.a
   WHEN MATCHED THEN UPDATE SET b = 'Updated';
 
 EXPLAIN (costs off)
 MERGE INTO rw_view1 t
-  USING (SELECT * FROM generate_series(1,5)) AS s(a) ON t.a = s.a
+  USING (SELECT * FROM generate_series(1,50)) AS s(a) ON t.a = s.a
   WHEN NOT MATCHED BY SOURCE THEN DELETE;
 
 EXPLAIN (costs off)
 MERGE INTO rw_view1 t
-  USING (SELECT * FROM generate_series(1,5)) AS s(a) ON t.a = s.a
+  USING (SELECT * FROM generate_series(1,50)) AS s(a) ON t.a = s.a
   WHEN NOT MATCHED THEN INSERT (a) VALUES (s.a);
 
 -- it's still updatable if we add a DO ALSO rule
diff --git a/src/test/regress/sql/vacuum.sql b/src/test/regress/sql/vacuum.sql
index d272dd064e..7e8d5ee86e 100644
--- a/src/test/regress/sql/vacuum.sql
+++ b/src/test/regress/sql/vacuum.sql
@@ -106,7 +106,7 @@ VACUUM (DISABLE_PAGE_SKIPPING) vaccluster;
 
 -- PARALLEL option
 CREATE TABLE pvactst (i INT, a INT[], p POINT) with (autovacuum_enabled = off);
-INSERT INTO pvactst SELECT i, array[1,2,3], point(i, i+1) FROM generate_series(1,1000) i;
+INSERT INTO pvactst SELECT i, array[1,2,3], point(i, i+1) FROM generate_series(1,10000) i;
 CREATE INDEX btree_pvactst ON pvactst USING btree (i);
 CREATE INDEX hash_pvactst ON pvactst USING hash (i);
 CREATE INDEX brin_pvactst ON pvactst USING brin (i);
@@ -156,7 +156,7 @@ CREATE TABLE no_index_cleanup (i INT PRIMARY KEY, t TEXT);
 -- Use uncompressed data stored in toast.
 CREATE INDEX no_index_cleanup_idx ON no_index_cleanup(t);
 ALTER TABLE no_index_cleanup ALTER COLUMN t SET STORAGE EXTERNAL;
-INSERT INTO no_index_cleanup(i, t) VALUES (generate_series(1,30),
+INSERT INTO no_index_cleanup(i, t) VALUES (generate_series(1,300),
     repeat('1234567890',269));
 -- index cleanup option is ignored if VACUUM FULL
 VACUUM (INDEX_CLEANUP TRUE, FULL TRUE) no_index_cleanup;
@@ -219,7 +219,7 @@ CREATE TABLE vacparted_i1 PARTITION OF vacparted_i
   FOR VALUES WITH (MODULUS 2, REMAINDER 0);
 CREATE TABLE vacparted_i2 PARTITION OF vacparted_i
   FOR VALUES WITH (MODULUS 2, REMAINDER 1);
-INSERT INTO vacparted_i SELECT i, 'test_'|| i from generate_series(1,10) i;
+INSERT INTO vacparted_i SELECT i, 'test_'|| i from generate_series(1,100) i;
 VACUUM (ANALYZE) vacparted_i;
 VACUUM (FULL) vacparted_i;
 VACUUM (FREEZE) vacparted_i;
diff --git a/src/test/regress/sql/window.sql b/src/test/regress/sql/window.sql
index 02f105f070..384228e081 100644
--- a/src/test/regress/sql/window.sql
+++ b/src/test/regress/sql/window.sql
@@ -155,7 +155,7 @@ select first_value(max(x)) over (), y
 
 -- window functions returning pass-by-ref values from different rows
 select x, lag(x, 1) over (order by x), lead(x, 3) over (order by x)
-from (select x::numeric as x from generate_series(1,10) x);
+from (select x::numeric as x from generate_series(1,100) x);
 
 -- test non-default frame specifications
 SELECT four, ten,
diff --git a/src/test/regress/sql/with.sql b/src/test/regress/sql/with.sql
index 6d55c7731a..1f4a118036 100644
--- a/src/test/regress/sql/with.sql
+++ b/src/test/regress/sql/with.sql
@@ -1276,7 +1276,7 @@ DROP RULE y_rule ON y;
 
 -- check merging of outer CTE with CTE in a rule action
 CREATE TEMP TABLE bug6051 AS
-  select i from generate_series(1,3) as t(i);
+  select i from generate_series(1,30) as t(i);
 
 SELECT * FROM bug6051;
 
